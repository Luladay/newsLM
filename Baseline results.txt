Baseline results (train)

Hyperparameters: 
-Adam Optimizer
-batch_size = 1000
-n_epochs = 1500
-lr = 0.005


Training:

Epoch 1:
=====>loss: 1.6013552

Epoch 1500:
=====>loss: 1.2796003


Testing (on test data):
Loss: 1.3418632

Micro F1 score: 44.76%
Macro F1 score: 39.18%
F1 score for New York Post:  0.0%
F1 score for Breitbart:  53.243%
F1 score for CNN:  56.087%
F1 score for Washington Post:  38.904%
F1 score for NPR:  47.69%


Testing (on train data):
Loss: 1.279171

Micro F1 score: 47.69%
Macro F1 score: 47.4%
F1 score for New York Post:  43.777%
F1 score for Breitbart:  54.292%
F1 score for CNN:  57.145%
F1 score for Washington Post:  35.359%
F1 score for NPR:  46.424%


Testing (on dev data):
Loss: 1.2995416

Micro F1 score: 46.17%
Macro F1 score: 45.23%
F1 score for New York Post:  34.6%
F1 score for Breitbart:  54.386%
F1 score for CNN:  57.044%
F1 score for Washington Post:  34.778%
F1 score for NPR:  45.318%
